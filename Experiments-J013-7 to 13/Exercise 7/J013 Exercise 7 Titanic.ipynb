{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "M1 J003.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlintyTub49/Sem_V-Machine-Learning/blob/master/Exercise%207/Exercise%207%20Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWMEuuKlEJqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a176a6fb-2471-4af6-a2c0-d24d0e7f4df2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPPltp9rEJqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLrRTYrYEJqt",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJiivDaLEJqy",
        "colab_type": "text"
      },
      "source": [
        "### Plotting a heatmap for the correlation between the variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B01-7BNEJq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "9b63bf02-5f26-4f89-e5da-6a64b9e150cd"
      },
      "source": [
        "sns.heatmap(train.corr(), annot = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e522945c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjmW6KilEJq_",
        "colab_type": "text"
      },
      "source": [
        "### Seeing the missing data and its data types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWq1yn1nEJrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d766af3b-bd1d-4ad1-8b06-f3665ae0ea07"
      },
      "source": [
        "print(train.info())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJMqM1yFEJrF",
        "colab_type": "text"
      },
      "source": [
        "### Dropping Passenger ID, Name and Ticket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ykb-tO4EJrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "84e00767-0709-4e82-c4fe-8b40d4526144"
      },
      "source": [
        "train = train.drop(['PassengerId', 'Name', 'Ticket'], axis = 1)\n",
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
              "0         0       3    male  22.0      1      0   7.2500   NaN        S\n",
              "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
              "2         1       3  female  26.0      0      0   7.9250   NaN        S\n",
              "3         1       1  female  35.0      1      0  53.1000  C123        S\n",
              "4         0       3    male  35.0      0      0   8.0500   NaN        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAf67OMEJrN",
        "colab_type": "text"
      },
      "source": [
        "### Seeing remainder of missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRn22upeEJrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def missing_values_table(df):\n",
        "        mis_val = df.isnull().sum()\n",
        "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1)\n",
        "        return mis_val_table_ren_columns"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMrIP_fdEJrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "5c34d02c-4f89-4958-80d0-efddf41b4933"
      },
      "source": [
        "missing_values_table(train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Values</th>\n",
              "      <th>% of Total Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cabin</th>\n",
              "      <td>687</td>\n",
              "      <td>77.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>177</td>\n",
              "      <td>19.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked</th>\n",
              "      <td>2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Missing Values  % of Total Values\n",
              "Cabin                687               77.1\n",
              "Age                  177               19.9\n",
              "Embarked               2                0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D6EX3SdEJrT",
        "colab_type": "text"
      },
      "source": [
        "### Since the Cabin variable has a lot of missing values, we drop it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqI01TK-EJrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "df8fcd7c-3018-40f0-88d6-e8baf6c6f344"
      },
      "source": [
        "train = train.drop(['Cabin'], axis = 1)\n",
        "train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
              "0         0       3    male  22.0      1      0   7.2500        S\n",
              "1         1       1  female  38.0      1      0  71.2833        C\n",
              "2         1       3  female  26.0      0      0   7.9250        S\n",
              "3         1       1  female  35.0      1      0  53.1000        S\n",
              "4         0       3    male  35.0      0      0   8.0500        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzJDlGZqEJrX",
        "colab_type": "text"
      },
      "source": [
        "### Replace the missing age values with the mean of rest of ages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZnTsRoiEJrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "be8e5609-f82a-4510-9a12-233443176fbf"
      },
      "source": [
        "train['Age'].fillna(train['Age'].mean(), inplace = True)\n",
        "train.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Survived  891 non-null    int64  \n",
            " 1   Pclass    891 non-null    int64  \n",
            " 2   Sex       891 non-null    object \n",
            " 3   Age       891 non-null    float64\n",
            " 4   SibSp     891 non-null    int64  \n",
            " 5   Parch     891 non-null    int64  \n",
            " 6   Fare      891 non-null    float64\n",
            " 7   Embarked  889 non-null    object \n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 55.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddAmYzimEJrb",
        "colab_type": "text"
      },
      "source": [
        "### Dropping the rows with na values in Embarked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zgdaW4kEJrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "030ffa77-0b34-4148-d5cb-8476eac37a6f"
      },
      "source": [
        "train = train.dropna()\n",
        "train.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 889 entries, 0 to 890\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Survived  889 non-null    int64  \n",
            " 1   Pclass    889 non-null    int64  \n",
            " 2   Sex       889 non-null    object \n",
            " 3   Age       889 non-null    float64\n",
            " 4   SibSp     889 non-null    int64  \n",
            " 5   Parch     889 non-null    int64  \n",
            " 6   Fare      889 non-null    float64\n",
            " 7   Embarked  889 non-null    object \n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 62.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJUW68CSEJre",
        "colab_type": "text"
      },
      "source": [
        "### Making Categories for Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuB9g89QEJre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "bd4d5765-2da3-4bb9-b1d1-0948437c7ded"
      },
      "source": [
        "cut_labels = [0, 1, 2, 3]\n",
        "cut_bins = [0, 13, 18, 60, 80]\n",
        "train['age_cat'] = pd.cut(train['Age'], bins = cut_bins, labels = cut_labels)\n",
        "train = train.drop('Age', axis = 1)\n",
        "train.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 889 entries, 0 to 890\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype   \n",
            "---  ------    --------------  -----   \n",
            " 0   Survived  889 non-null    int64   \n",
            " 1   Pclass    889 non-null    int64   \n",
            " 2   Sex       889 non-null    object  \n",
            " 3   SibSp     889 non-null    int64   \n",
            " 4   Parch     889 non-null    int64   \n",
            " 5   Fare      889 non-null    float64 \n",
            " 6   Embarked  889 non-null    object  \n",
            " 7   age_cat   889 non-null    category\n",
            "dtypes: category(1), float64(1), int64(4), object(2)\n",
            "memory usage: 56.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wB2uhIaEJrh",
        "colab_type": "text"
      },
      "source": [
        "### Converting PClass, Sex and Embarked to category data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWCcHH9EJrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "418f92bf-2166-4333-c1b4-ac9fcd7df21f"
      },
      "source": [
        "train['Pclass'] = train['Pclass'].astype('category')\n",
        "train['Sex'] = train['Sex'].astype('category')\n",
        "train['Embarked'] = train['Embarked'].astype('category')\n",
        "train.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 889 entries, 0 to 890\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype   \n",
            "---  ------    --------------  -----   \n",
            " 0   Survived  889 non-null    int64   \n",
            " 1   Pclass    889 non-null    category\n",
            " 2   Sex       889 non-null    category\n",
            " 3   SibSp     889 non-null    int64   \n",
            " 4   Parch     889 non-null    int64   \n",
            " 5   Fare      889 non-null    float64 \n",
            " 6   Embarked  889 non-null    category\n",
            " 7   age_cat   889 non-null    category\n",
            "dtypes: category(4), float64(1), int64(3)\n",
            "memory usage: 38.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBbSve5SEJrk",
        "colab_type": "text"
      },
      "source": [
        "### Making a new column for total family"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Ci11vcEJrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train['FamilyS'] = train['SibSp'] + train['Parch'] + 1\n",
        "# train['IsAlone'] = 1\n",
        "# train['IsAlone'].loc[train['FamilyS'] > 1] = 0\n",
        "# train.info()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4jtdSc-EJro",
        "colab_type": "text"
      },
      "source": [
        "### One hot encoding all categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9QHJES-EJrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "665827e5-bace-4b91-cc72-af110604355c"
      },
      "source": [
        "train = pd.get_dummies(train)\n",
        "train.info()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 889 entries, 0 to 890\n",
            "Data columns (total 16 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Survived    889 non-null    int64  \n",
            " 1   SibSp       889 non-null    int64  \n",
            " 2   Parch       889 non-null    int64  \n",
            " 3   Fare        889 non-null    float64\n",
            " 4   Pclass_1    889 non-null    uint8  \n",
            " 5   Pclass_2    889 non-null    uint8  \n",
            " 6   Pclass_3    889 non-null    uint8  \n",
            " 7   Sex_female  889 non-null    uint8  \n",
            " 8   Sex_male    889 non-null    uint8  \n",
            " 9   Embarked_C  889 non-null    uint8  \n",
            " 10  Embarked_Q  889 non-null    uint8  \n",
            " 11  Embarked_S  889 non-null    uint8  \n",
            " 12  age_cat_0   889 non-null    uint8  \n",
            " 13  age_cat_1   889 non-null    uint8  \n",
            " 14  age_cat_2   889 non-null    uint8  \n",
            " 15  age_cat_3   889 non-null    uint8  \n",
            "dtypes: float64(1), int64(3), uint8(12)\n",
            "memory usage: 45.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEq3TS0VEJrr",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdbOG_n3EJrs",
        "colab_type": "text"
      },
      "source": [
        "### Splitting X and Y variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNgfyHQUEJrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train.drop('Survived', axis = 1)\n",
        "y = train['Survived']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kd2Pg2AEJru",
        "colab_type": "text"
      },
      "source": [
        "### Splitting data into train, dev and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8csNfkDEJrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ef587b00-b11f-4295-be76-60bd4444accf"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "# x_dev, x_test, y_dev, y_test = train_test_split(x_test, y_test, test_size = 0.5)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "# print(x_dev.shape)\n",
        "# print(y_dev.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(711, 15)\n",
            "(711,)\n",
            "(178, 15)\n",
            "(178,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5C-ldqGEJrx",
        "colab_type": "text"
      },
      "source": [
        "### Defining The Classifier Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_vY2QxeEJry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistics = linear_model.LogisticRegression()\n",
        "sgd = linear_model.SGDClassifier()\n",
        "passagg = linear_model.PassiveAggressiveClassifier()\n",
        "ridgecv = linear_model.RidgeClassifierCV()\n",
        "ridgeclass = linear_model.RidgeClassifier()\n",
        "\n",
        "models_log = [logistics, sgd, passagg, ridgecv, ridgeclass]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_PfQ6_UEJr0",
        "colab_type": "text"
      },
      "source": [
        "### Defining A Cross Val Function To Be Called Several Times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UnyhPT_EJr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cv_scores(model):\n",
        "    scores = cross_val_score(model, x_train, y_train, cv = 10, scoring='accuracy')\n",
        "    print('CV Mean: ', np.mean(scores))\n",
        "    print('STD: ', np.std(scores))\n",
        "    print('\\n')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ2NjNzoEJr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "a7d9d717-57e1-4828-f2ea-d6332355429b"
      },
      "source": [
        "for i in models_log:\n",
        "    print(i)\n",
        "    get_cv_scores(i)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "CV Mean:  0.8030125195618154\n",
            "STD:  0.033664173486319345\n",
            "\n",
            "\n",
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
            "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "CV Mean:  0.7522887323943662\n",
            "STD:  0.07217043001161827\n",
            "\n",
            "\n",
            "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
            "                            early_stopping=False, fit_intercept=True,\n",
            "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
            "                            n_jobs=None, random_state=None, shuffle=True,\n",
            "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
            "                            warm_start=False)\n",
            "CV Mean:  0.6833137715179969\n",
            "STD:  0.11161782073593261\n",
            "\n",
            "\n",
            "RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]), class_weight=None, cv=None,\n",
            "                  fit_intercept=True, normalize=False, scoring=None,\n",
            "                  store_cv_values=False)\n",
            "CV Mean:  0.805868544600939\n",
            "STD:  0.0333969174686743\n",
            "\n",
            "\n",
            "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "                max_iter=None, normalize=False, random_state=None,\n",
            "                solver='auto', tol=0.001)\n",
            "CV Mean:  0.8086658841940533\n",
            "STD:  0.03187440992569534\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz8crcrhEJr6",
        "colab_type": "text"
      },
      "source": [
        "### Defining the parameters for GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPq9EGxrEJr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penalty = ['l1', 'l2']\n",
        "C = [0.0001, 0.001, 0.01]\n",
        "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}]\n",
        "solver = ['liblinear', 'saga']\n",
        "\n",
        "param_grid = dict(penalty=penalty,\n",
        "                  C=C,\n",
        "                  class_weight=class_weight,\n",
        "                  solver=solver)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXGFgRY5EJr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "399ac1c9-e449-4fce-ed99-1a389e5363f2"
      },
      "source": [
        "grid = GridSearchCV(estimator = logistics, param_grid = param_grid, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "pred = grid.predict(x_test)\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    1.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7865168539325843"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru040LajEJr-",
        "colab_type": "text"
      },
      "source": [
        "### Trying to get a better accuracy with Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BapjtCDPEJr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Bo9x2gEJsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = models.Sequential()\n",
        "nn.add(layers.Dense(1024, activation=\"relu\",input_shape=(15,)))\n",
        "nn.add(layers.Dense(512, activation=\"relu\"))\n",
        "nn.add(layers.Dense(256, activation=\"relu\"))\n",
        "nn.add(layers.Dense(128, activation=\"relu\"))\n",
        "nn.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "nn.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I70cbNOjEJsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a414671-ee13-4a50-85f5-379867665a3d"
      },
      "source": [
        "filepath = \"Best Model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode='max', verbose = 1)\n",
        "es = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 50, verbose = 1)\n",
        "call_list = [checkpoint, es]\n",
        "nn.fit(x_train, y_train, epochs = 1000, batch_size = 200, validation_split = 0.3, callbacks = call_list)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.7381 - accuracy: 0.3550\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.39252, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 2.5087 - accuracy: 0.5010 - val_loss: 1.9639 - val_accuracy: 0.3925\n",
            "Epoch 2/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.2887 - accuracy: 0.4150\n",
            "Epoch 00002: val_accuracy improved from 0.39252 to 0.61215, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.4733 - accuracy: 0.4990 - val_loss: 0.9241 - val_accuracy: 0.6121\n",
            "Epoch 3/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.1783 - accuracy: 0.5950\n",
            "Epoch 00003: val_accuracy did not improve from 0.61215\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0603 - accuracy: 0.5211 - val_loss: 0.7069 - val_accuracy: 0.5748\n",
            "Epoch 4/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6490 - accuracy: 0.6100\n",
            "Epoch 00004: val_accuracy did not improve from 0.61215\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7194 - accuracy: 0.6700 - val_loss: 1.3066 - val_accuracy: 0.3925\n",
            "Epoch 5/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0518 - accuracy: 0.4250\n",
            "Epoch 00005: val_accuracy did not improve from 0.61215\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8521 - accuracy: 0.5030 - val_loss: 0.6601 - val_accuracy: 0.6121\n",
            "Epoch 6/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6585 - accuracy: 0.6000\n",
            "Epoch 00006: val_accuracy did not improve from 0.61215\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.7046 - accuracy: 0.5795 - val_loss: 1.0495 - val_accuracy: 0.5654\n",
            "Epoch 7/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.7362 - accuracy: 0.6100\n",
            "Epoch 00007: val_accuracy improved from 0.61215 to 0.65421, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6645 - accuracy: 0.6579 - val_loss: 0.7055 - val_accuracy: 0.6542\n",
            "Epoch 8/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5806 - accuracy: 0.6900\n",
            "Epoch 00008: val_accuracy did not improve from 0.65421\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7849 - accuracy: 0.6016 - val_loss: 0.6980 - val_accuracy: 0.6542\n",
            "Epoch 9/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6061 - accuracy: 0.7250\n",
            "Epoch 00009: val_accuracy did not improve from 0.65421\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6495 - accuracy: 0.6700 - val_loss: 0.6692 - val_accuracy: 0.6542\n",
            "Epoch 10/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5449 - accuracy: 0.7500\n",
            "Epoch 00010: val_accuracy did not improve from 0.65421\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6414 - accuracy: 0.6962 - val_loss: 1.4928 - val_accuracy: 0.5794\n",
            "Epoch 11/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.2569 - accuracy: 0.5800\n",
            "Epoch 00011: val_accuracy did not improve from 0.65421\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8452 - accuracy: 0.6620 - val_loss: 0.7932 - val_accuracy: 0.6262\n",
            "Epoch 12/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6198 - accuracy: 0.7350\n",
            "Epoch 00012: val_accuracy improved from 0.65421 to 0.67757, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6388 - accuracy: 0.6740 - val_loss: 0.6387 - val_accuracy: 0.6776\n",
            "Epoch 13/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5125 - accuracy: 0.7350\n",
            "Epoch 00013: val_accuracy did not improve from 0.67757\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5561 - accuracy: 0.6841 - val_loss: 0.7131 - val_accuracy: 0.6589\n",
            "Epoch 14/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5233 - accuracy: 0.7650\n",
            "Epoch 00014: val_accuracy did not improve from 0.67757\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5185 - accuracy: 0.7586 - val_loss: 0.6406 - val_accuracy: 0.6542\n",
            "Epoch 15/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5696 - accuracy: 0.7100\n",
            "Epoch 00015: val_accuracy improved from 0.67757 to 0.68224, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5289 - accuracy: 0.7143 - val_loss: 0.7014 - val_accuracy: 0.6822\n",
            "Epoch 16/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5015 - accuracy: 0.7650\n",
            "Epoch 00016: val_accuracy did not improve from 0.68224\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5314 - accuracy: 0.7384 - val_loss: 0.6146 - val_accuracy: 0.6121\n",
            "Epoch 17/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5740 - accuracy: 0.6450\n",
            "Epoch 00017: val_accuracy did not improve from 0.68224\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.7022 - val_loss: 0.5965 - val_accuracy: 0.6729\n",
            "Epoch 18/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5026 - accuracy: 0.7550\n",
            "Epoch 00018: val_accuracy improved from 0.68224 to 0.68692, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.5002 - accuracy: 0.7364 - val_loss: 0.6510 - val_accuracy: 0.6869\n",
            "Epoch 19/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4966 - accuracy: 0.7950\n",
            "Epoch 00019: val_accuracy improved from 0.68692 to 0.69626, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.4865 - accuracy: 0.7726 - val_loss: 0.5981 - val_accuracy: 0.6963\n",
            "Epoch 20/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4899 - accuracy: 0.7700\n",
            "Epoch 00020: val_accuracy did not improve from 0.69626\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.7485 - val_loss: 0.5926 - val_accuracy: 0.6121\n",
            "Epoch 21/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5811 - accuracy: 0.6050\n",
            "Epoch 00021: val_accuracy did not improve from 0.69626\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6193 - accuracy: 0.6640 - val_loss: 0.5509 - val_accuracy: 0.6495\n",
            "Epoch 22/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4840 - accuracy: 0.7400\n",
            "Epoch 00022: val_accuracy did not improve from 0.69626\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5214 - accuracy: 0.7465 - val_loss: 0.5760 - val_accuracy: 0.6822\n",
            "Epoch 23/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5370 - accuracy: 0.7650\n",
            "Epoch 00023: val_accuracy did not improve from 0.69626\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5581 - accuracy: 0.7505 - val_loss: 0.5794 - val_accuracy: 0.6121\n",
            "Epoch 24/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5498 - accuracy: 0.6300\n",
            "Epoch 00024: val_accuracy did not improve from 0.69626\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5305 - accuracy: 0.7022 - val_loss: 0.5982 - val_accuracy: 0.6869\n",
            "Epoch 25/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5049 - accuracy: 0.8000\n",
            "Epoch 00025: val_accuracy did not improve from 0.69626\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.8109 - val_loss: 0.7025 - val_accuracy: 0.6963\n",
            "Epoch 26/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5663 - accuracy: 0.7250\n",
            "Epoch 00026: val_accuracy improved from 0.69626 to 0.72430, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5206 - accuracy: 0.7867 - val_loss: 0.5645 - val_accuracy: 0.7243\n",
            "Epoch 27/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4464 - accuracy: 0.8000\n",
            "Epoch 00027: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7928 - val_loss: 0.7704 - val_accuracy: 0.7150\n",
            "Epoch 28/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5401 - accuracy: 0.7500\n",
            "Epoch 00028: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4923 - accuracy: 0.7847 - val_loss: 0.5862 - val_accuracy: 0.6542\n",
            "Epoch 29/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5997 - accuracy: 0.6900\n",
            "Epoch 00029: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5962 - accuracy: 0.7103 - val_loss: 0.6188 - val_accuracy: 0.7196\n",
            "Epoch 30/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4754 - accuracy: 0.7650\n",
            "Epoch 00030: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.7867 - val_loss: 0.5880 - val_accuracy: 0.7150\n",
            "Epoch 31/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4306 - accuracy: 0.8550\n",
            "Epoch 00031: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5785 - accuracy: 0.7425 - val_loss: 0.6743 - val_accuracy: 0.7103\n",
            "Epoch 32/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4861 - accuracy: 0.7550\n",
            "Epoch 00032: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4917 - accuracy: 0.7485 - val_loss: 0.7108 - val_accuracy: 0.7196\n",
            "Epoch 33/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5305 - accuracy: 0.7600\n",
            "Epoch 00033: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4833 - accuracy: 0.7827 - val_loss: 1.0532 - val_accuracy: 0.6121\n",
            "Epoch 34/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0651 - accuracy: 0.6050\n",
            "Epoch 00034: val_accuracy did not improve from 0.72430\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7601 - accuracy: 0.6861 - val_loss: 0.5474 - val_accuracy: 0.7103\n",
            "Epoch 35/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4881 - accuracy: 0.8300\n",
            "Epoch 00035: val_accuracy improved from 0.72430 to 0.73364, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.4895 - accuracy: 0.8109 - val_loss: 0.5419 - val_accuracy: 0.7336\n",
            "Epoch 36/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4909 - accuracy: 0.7750\n",
            "Epoch 00036: val_accuracy did not improve from 0.73364\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.8008 - val_loss: 0.6335 - val_accuracy: 0.7196\n",
            "Epoch 37/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3974 - accuracy: 0.8500\n",
            "Epoch 00037: val_accuracy did not improve from 0.73364\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7948 - val_loss: 0.7209 - val_accuracy: 0.7243\n",
            "Epoch 38/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5757 - accuracy: 0.7300\n",
            "Epoch 00038: val_accuracy did not improve from 0.73364\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.7847 - val_loss: 0.6429 - val_accuracy: 0.7336\n",
            "Epoch 39/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4599 - accuracy: 0.8100\n",
            "Epoch 00039: val_accuracy did not improve from 0.73364\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.8209 - val_loss: 0.8024 - val_accuracy: 0.7150\n",
            "Epoch 40/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5546 - accuracy: 0.7650\n",
            "Epoch 00040: val_accuracy did not improve from 0.73364\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7887 - val_loss: 0.5829 - val_accuracy: 0.7290\n",
            "Epoch 41/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4081 - accuracy: 0.8150\n",
            "Epoch 00041: val_accuracy did not improve from 0.73364\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.7726 - val_loss: 0.7489 - val_accuracy: 0.7103\n",
            "Epoch 42/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5366 - accuracy: 0.7450\n",
            "Epoch 00042: val_accuracy did not improve from 0.73364\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5006 - accuracy: 0.7525 - val_loss: 0.6618 - val_accuracy: 0.7196\n",
            "Epoch 43/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4346 - accuracy: 0.8200\n",
            "Epoch 00043: val_accuracy improved from 0.73364 to 0.77570, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4801 - accuracy: 0.7948 - val_loss: 0.5596 - val_accuracy: 0.7757\n",
            "Epoch 44/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5351 - accuracy: 0.7950\n",
            "Epoch 00044: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.8109 - val_loss: 0.6249 - val_accuracy: 0.7477\n",
            "Epoch 45/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3882 - accuracy: 0.8550\n",
            "Epoch 00045: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.8310 - val_loss: 0.8384 - val_accuracy: 0.7196\n",
            "Epoch 46/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5738 - accuracy: 0.7750\n",
            "Epoch 00046: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.7948 - val_loss: 0.6582 - val_accuracy: 0.7243\n",
            "Epoch 47/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4293 - accuracy: 0.8200\n",
            "Epoch 00047: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8310 - val_loss: 0.5856 - val_accuracy: 0.7477\n",
            "Epoch 48/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4727 - accuracy: 0.8000\n",
            "Epoch 00048: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4947 - accuracy: 0.7686 - val_loss: 0.5613 - val_accuracy: 0.7290\n",
            "Epoch 49/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4824 - accuracy: 0.7750\n",
            "Epoch 00049: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4638 - accuracy: 0.8048 - val_loss: 0.5283 - val_accuracy: 0.7570\n",
            "Epoch 50/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4470 - accuracy: 0.8100\n",
            "Epoch 00050: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8189 - val_loss: 0.5418 - val_accuracy: 0.7617\n",
            "Epoch 51/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4091 - accuracy: 0.8350\n",
            "Epoch 00051: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8290 - val_loss: 0.5298 - val_accuracy: 0.7710\n",
            "Epoch 52/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3732 - accuracy: 0.8550\n",
            "Epoch 00052: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.8109 - val_loss: 0.5976 - val_accuracy: 0.7196\n",
            "Epoch 53/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4355 - accuracy: 0.8300\n",
            "Epoch 00053: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.8129 - val_loss: 0.5038 - val_accuracy: 0.7617\n",
            "Epoch 54/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4198 - accuracy: 0.8450\n",
            "Epoch 00054: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8330 - val_loss: 0.6003 - val_accuracy: 0.7523\n",
            "Epoch 55/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3633 - accuracy: 0.8600\n",
            "Epoch 00055: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4016 - accuracy: 0.8249 - val_loss: 0.5311 - val_accuracy: 0.7664\n",
            "Epoch 56/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3948 - accuracy: 0.8200\n",
            "Epoch 00056: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6072 - accuracy: 0.7404 - val_loss: 0.6019 - val_accuracy: 0.7243\n",
            "Epoch 57/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4281 - accuracy: 0.8000\n",
            "Epoch 00057: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8249 - val_loss: 0.4945 - val_accuracy: 0.7710\n",
            "Epoch 58/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3752 - accuracy: 0.8500\n",
            "Epoch 00058: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8370 - val_loss: 0.5064 - val_accuracy: 0.7710\n",
            "Epoch 59/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4405 - accuracy: 0.8200\n",
            "Epoch 00059: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5090 - accuracy: 0.7847 - val_loss: 0.4991 - val_accuracy: 0.7617\n",
            "Epoch 60/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4060 - accuracy: 0.8350\n",
            "Epoch 00060: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8270 - val_loss: 0.5131 - val_accuracy: 0.7664\n",
            "Epoch 61/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4443 - accuracy: 0.8300\n",
            "Epoch 00061: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.8109 - val_loss: 0.6341 - val_accuracy: 0.7243\n",
            "Epoch 62/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3762 - accuracy: 0.8350\n",
            "Epoch 00062: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8330 - val_loss: 0.6125 - val_accuracy: 0.7430\n",
            "Epoch 63/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3772 - accuracy: 0.8400\n",
            "Epoch 00063: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8189 - val_loss: 0.9572 - val_accuracy: 0.7196\n",
            "Epoch 64/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4850 - accuracy: 0.7400\n",
            "Epoch 00064: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7746 - val_loss: 0.6424 - val_accuracy: 0.7290\n",
            "Epoch 65/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3965 - accuracy: 0.8400\n",
            "Epoch 00065: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8270 - val_loss: 0.5170 - val_accuracy: 0.7710\n",
            "Epoch 66/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4049 - accuracy: 0.8400\n",
            "Epoch 00066: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.8109 - val_loss: 0.5330 - val_accuracy: 0.7570\n",
            "Epoch 67/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3890 - accuracy: 0.8050\n",
            "Epoch 00067: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8209 - val_loss: 0.6077 - val_accuracy: 0.7477\n",
            "Epoch 68/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4338 - accuracy: 0.8250\n",
            "Epoch 00068: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8068 - val_loss: 0.5765 - val_accuracy: 0.7430\n",
            "Epoch 69/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3672 - accuracy: 0.8250\n",
            "Epoch 00069: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8350 - val_loss: 0.8176 - val_accuracy: 0.7150\n",
            "Epoch 70/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4388 - accuracy: 0.8300\n",
            "Epoch 00070: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8330 - val_loss: 0.5612 - val_accuracy: 0.7243\n",
            "Epoch 71/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3905 - accuracy: 0.8350\n",
            "Epoch 00071: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8290 - val_loss: 0.5454 - val_accuracy: 0.7710\n",
            "Epoch 72/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8450\n",
            "Epoch 00072: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8310 - val_loss: 0.5711 - val_accuracy: 0.7523\n",
            "Epoch 73/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2808 - accuracy: 0.8900\n",
            "Epoch 00073: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8471 - val_loss: 0.5615 - val_accuracy: 0.6963\n",
            "Epoch 74/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6114 - accuracy: 0.6850\n",
            "Epoch 00074: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4975 - accuracy: 0.7686 - val_loss: 0.5161 - val_accuracy: 0.7617\n",
            "Epoch 75/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3791 - accuracy: 0.8400\n",
            "Epoch 00075: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4779 - accuracy: 0.8048 - val_loss: 0.7647 - val_accuracy: 0.7336\n",
            "Epoch 76/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3663 - accuracy: 0.8300\n",
            "Epoch 00076: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8089 - val_loss: 0.5076 - val_accuracy: 0.7710\n",
            "Epoch 77/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4631 - accuracy: 0.8000\n",
            "Epoch 00077: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8410 - val_loss: 0.5815 - val_accuracy: 0.7150\n",
            "Epoch 78/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3797 - accuracy: 0.8300\n",
            "Epoch 00078: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8370 - val_loss: 0.6883 - val_accuracy: 0.6916\n",
            "Epoch 79/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6309 - accuracy: 0.6850\n",
            "Epoch 00079: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5098 - accuracy: 0.7706 - val_loss: 0.5904 - val_accuracy: 0.7103\n",
            "Epoch 80/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3656 - accuracy: 0.8250\n",
            "Epoch 00080: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8370 - val_loss: 0.7119 - val_accuracy: 0.7196\n",
            "Epoch 81/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3597 - accuracy: 0.8350\n",
            "Epoch 00081: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8270 - val_loss: 0.4956 - val_accuracy: 0.7570\n",
            "Epoch 82/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3606 - accuracy: 0.8450\n",
            "Epoch 00082: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5064 - val_accuracy: 0.7523\n",
            "Epoch 83/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3870 - accuracy: 0.8300\n",
            "Epoch 00083: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.8410 - val_loss: 0.5556 - val_accuracy: 0.7570\n",
            "Epoch 84/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2796 - accuracy: 0.8700\n",
            "Epoch 00084: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8189 - val_loss: 0.5097 - val_accuracy: 0.7336\n",
            "Epoch 85/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3928 - accuracy: 0.8500\n",
            "Epoch 00085: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8390 - val_loss: 0.5865 - val_accuracy: 0.7617\n",
            "Epoch 86/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3383 - accuracy: 0.8650\n",
            "Epoch 00086: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3701 - accuracy: 0.8511 - val_loss: 0.7414 - val_accuracy: 0.7243\n",
            "Epoch 87/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3824 - accuracy: 0.8500\n",
            "Epoch 00087: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8270 - val_loss: 0.5459 - val_accuracy: 0.7243\n",
            "Epoch 88/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4238 - accuracy: 0.8050\n",
            "Epoch 00088: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3663 - accuracy: 0.8350 - val_loss: 0.5905 - val_accuracy: 0.7617\n",
            "Epoch 89/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4102 - accuracy: 0.8200\n",
            "Epoch 00089: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.8149 - val_loss: 0.5726 - val_accuracy: 0.7664\n",
            "Epoch 90/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4056 - accuracy: 0.8500\n",
            "Epoch 00090: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.8390 - val_loss: 0.5350 - val_accuracy: 0.7570\n",
            "Epoch 91/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8700\n",
            "Epoch 00091: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3526 - accuracy: 0.8410 - val_loss: 0.8333 - val_accuracy: 0.7336\n",
            "Epoch 92/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4693 - accuracy: 0.8500\n",
            "Epoch 00092: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.8048 - val_loss: 0.5367 - val_accuracy: 0.7150\n",
            "Epoch 93/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4287 - accuracy: 0.8100\n",
            "Epoch 00093: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3794 - accuracy: 0.8350 - val_loss: 0.5459 - val_accuracy: 0.7477\n",
            "Epoch 94/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8850\n",
            "Epoch 00094: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3536 - accuracy: 0.8531 - val_loss: 0.6551 - val_accuracy: 0.7336\n",
            "Epoch 95/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4196 - accuracy: 0.8250\n",
            "Epoch 00095: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8390 - val_loss: 0.5364 - val_accuracy: 0.7617\n",
            "Epoch 96/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3471 - accuracy: 0.8550\n",
            "Epoch 00096: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8451 - val_loss: 0.6003 - val_accuracy: 0.7243\n",
            "Epoch 97/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3700 - accuracy: 0.8400\n",
            "Epoch 00097: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.8471 - val_loss: 0.8182 - val_accuracy: 0.7243\n",
            "Epoch 98/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4636 - accuracy: 0.7750\n",
            "Epoch 00098: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.8310 - val_loss: 0.6368 - val_accuracy: 0.7430\n",
            "Epoch 99/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3270 - accuracy: 0.8400\n",
            "Epoch 00099: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3722 - accuracy: 0.8229 - val_loss: 0.5803 - val_accuracy: 0.7430\n",
            "Epoch 100/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3898 - accuracy: 0.8200\n",
            "Epoch 00100: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.8451 - val_loss: 0.7986 - val_accuracy: 0.7290\n",
            "Epoch 101/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8400\n",
            "Epoch 00101: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8451 - val_loss: 0.5479 - val_accuracy: 0.7757\n",
            "Epoch 102/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3941 - accuracy: 0.8250\n",
            "Epoch 00102: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8410 - val_loss: 0.6581 - val_accuracy: 0.7243\n",
            "Epoch 103/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3580 - accuracy: 0.8200\n",
            "Epoch 00103: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3698 - accuracy: 0.8471 - val_loss: 0.5142 - val_accuracy: 0.7570\n",
            "Epoch 104/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4689 - accuracy: 0.7700\n",
            "Epoch 00104: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.7887 - val_loss: 0.5073 - val_accuracy: 0.7290\n",
            "Epoch 105/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8050\n",
            "Epoch 00105: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8431 - val_loss: 0.8221 - val_accuracy: 0.7664\n",
            "Epoch 106/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5236 - accuracy: 0.8050\n",
            "Epoch 00106: val_accuracy did not improve from 0.77570\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.8229 - val_loss: 0.4986 - val_accuracy: 0.7664\n",
            "Epoch 107/1000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3662 - accuracy: 0.8450\n",
            "Epoch 00107: val_accuracy improved from 0.77570 to 0.78505, saving model to Best Model.hdf5\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3542 - accuracy: 0.8451 - val_loss: 0.5387 - val_accuracy: 0.7850\n",
            "Epoch 00107: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e100d1f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QvGoT0DKFuq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "24b6c060-7442-4683-c20e-d4e107771c15"
      },
      "source": [
        "saved_model = load_model('Best Model.hdf5')\n",
        "saved_model.evaluate(x_test, y_test)[1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.8090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8089887499809265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cClqcOz7EJsH",
        "colab_type": "text"
      },
      "source": [
        "### Trying Random Forest Classifier - Experimental"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPTK3wVMEJsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cea8e0d-d0bf-41da-e814-95379af30cad"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(criterion='gini', n_estimators=700,\n",
        "                             min_samples_split=10,min_samples_leaf=1,\n",
        "                             max_features='auto',oob_score=True,\n",
        "                             random_state=1,n_jobs=-1)\n",
        "model.fit(x_train,y_train)\n",
        "prediction_rm = model.predict(x_test)\n",
        "accuracy_score(y_test, prediction_rm)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8089887640449438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HlpYwmEJsJ",
        "colab_type": "text"
      },
      "source": [
        "### Trying SVM - Experimental"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWOeX_FnEJsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a660312-ed03-4bd1-b67c-44b258a9772f"
      },
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "model_svc = SVC()\n",
        "model_svc.fit(x_train, y_train)\n",
        "prediction_svm=model_svc.predict(x_test)\n",
        "accuracy_score(y_test, prediction_svm)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6797752808988764"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISko9y-fEJsM",
        "colab_type": "text"
      },
      "source": [
        "Since our best model yet was with Logistic Regression, we consider it to be the best model and find the accuracy on the test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Qz5BZpEJsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5298ee0e-ad76-4257-8530-a0a238eb4648"
      },
      "source": [
        "logistics.fit(x_train, y_train)\n",
        "\n",
        "# pred_logi_dev = logistics.predict(x_dev)\n",
        "# print(accuracy_score(y_dev, pred_logi_dev))\n",
        "\n",
        "pred_logi_test = logistics.predict(x_test)\n",
        "print(accuracy_score(y_test, pred_logi_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7921348314606742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxWsWu7EEJsO",
        "colab_type": "text"
      },
      "source": [
        "The hyperparamters of our model are :-<br>\n",
        "\n",
        "C = 1.0 <br>\n",
        "class_weight = None<br>\n",
        "dual = False<br>\n",
        "fit_intercept = True<br>\n",
        "intercept_scaling = 1 <br>\n",
        "l1_ratio = None<br>\n",
        "max_iter = 100<br>\n",
        "multi_class = 'auto'<br>\n",
        "n_jobs  =None<br>\n",
        "penalty = 'l2'<br>\n",
        "random_state = None <br>\n",
        "solver = 'lbfgs'<br>\n",
        "tol = 0.0001<br>\n",
        "verbose = 0<br>\n",
        "warm_start = False<br>"
      ]
    }
  ]
}